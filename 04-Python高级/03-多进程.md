#####1.进程：一个程序运行起来后，代码+用到的资源 称之为进程，它是操作系统分配资源的基本单元 
#####2.使用多进程的基本步骤
>    1. 导入`multiprocessing` 模块，或者精确导入`multiprocessing.Process`类
>    2. 创建`Process`对象，构造函数中传入子进程要执行的函数名和参数
>    3. `start`方法开启子进程 

**代码示例：**
 
```python

	import multiprocessing
	import threading
	import time
	
	
	def test1(sleep_time):
	    while True:
	        time.sleep(sleep_time)
	        print("-----test1-----processName= "+multiprocessing.current_process().name+" ;threadName= "+threading.current_thread().getName())
	        # -----test1-----processName= Process-1 ;threadName= MainThread
	        # 每个进程里默认都有个主线程
	
	
	def test2(sleep_time):
	    while True:
	        time.sleep(sleep_time)
	        print("-----test2-----processName=" + multiprocessing.current_process().name+" ;threadName= "+threading.current_thread().getName())
	        # -----test2-----processName=Process-2 ;threadName= MainThread
	        # 每个进程里默认都有个主线程
	
	
	def main():
	    # 获取cpu核心数
	    cpu_count=multiprocessing.cpu_count()
	    print("cpu_count="+str(cpu_count))
	
	    # 创建多进程
	    process1 = multiprocessing.Process(target=test1, args=(1,))
	    process2 = multiprocessing.Process(target=test2, args=(1,))
	    # 开启多进程
	    process1.start()
	    process2.start()
	    print("-----main-----processName=" + multiprocessing.current_process().name + " ;threadName= " + threading.current_thread().getName())
	    # -----main-----processName=MainProcess ;threadName= MainThread
	
	    process1.join(5) # process1阻塞主进程5秒
	    print("5 second later")
	    process1.join(5) # process2阻塞主进程5秒
	    print("5 second later") # process1 和 process2 一共阻塞主进程10秒，10秒后才能打印该行
	
	
	if __name__ == "__main__":
		main()
```  

**注意事项：**

	1. multiprocessing.current_process().name 能够获取当前进程名
	2. os.getpid() 能够获得当前进程的进程号（pid） 
 	3. 子进程的join(time) 方法可以阻塞主进程指定的时间，即主进程等待该子进程time时间后继续执行；
	   不传参数表示主进程等待子进程执行完毕才能继续执行
		a:子进程都不调用join方法，那么主进程不阻塞，主进程和子进程同时运行。主进程等待所有子进程运行结束，程序结束
		b:子进程调用了join方法，主进程阻塞，这时主进程的代码不继续向下执行，等待所有子进程阻塞结束，主进程继续执行，程序结束 
	4. process = mulprocessing.Process(target="doingsomeing", args=()) 只是创建了进程对象，并没有真正创建一个进程，只有在调用start()方法时，系统才会开启一个新进程，这一点和线程类似    
	
#####3.进程队列（Queue）
	进程之间有时需要通信，可以有多种方法，比如文件、跨进程的socket，还可以用multiporcessing的Queue来实现
使用Queue的基本步骤:

> 1. 导入`multiprocessing` 模块，或者精确导入`multiprocessing.Queue`类
> 2. 创建Queue对象，创建多进程
> 3. 不同的进程间用`queue.put（）`放数据，`queue.get（）`取数据 

代码示例： 
```python

	import multiprocessing
	
	def download_from_web(q):
	    # 模拟从网上下载的数据
	    data = ["c","c#","c++","java","python"]
	
	    for temp in data:
	        q.put(temp)
	        if q.full():
	            break
	    print("-----下载器已经下载完数据并且存放到共享队列中-----")
	
	
	def analysis_data(q):
	    waiting_analysis_data = []
	    # 从列队中获取数据
	    while True:
	        data = q.get()
	        waiting_analysis_data.append(data)
	
	        if q.empty():
	            break
	    print("分析器已经分析的数据："+str(waiting_analysis_data))
	
	
	def main():
	    q = multiprocessing.Queue(5)
	    download_process = multiprocessing.Process(target=download_from_web(q))
	    analysis_process = multiprocessing.Process(target=analysis_data(q))
	
	    download_process.start()
	    analysis_process.start()
	
	
	if __name__ == "__main__":
		main()
```

**注意事项** :
	
	queue = multiprocessing.Queue(3) 参数表示该队列最多存放的数据个数，数据可以是任意类型
	queue.put() 往队列中添加一个数据，队列中的数据数量加1
	queue.get() 从队列中获取数据，如果有就按先进先出的规则获取一个，队列中的数据数量减一，如果队列中是empty，则阻塞，直到获取到数据为止
	queue.full() 判断队列是否满了
	queue.empty() 判断队列是否为空
	queue.get_nowait() 不等待直接从队列中获取数据，不管队列中是否有数据，如果没有就报错 

#####4.进程池(Pool) 
	
使用进程池的基本步骤：
> 1. 导入`multiprocessing` 或者 精确导入 `multiprocessing.Pool` 
> 2. 创建进程池对象pool = multiprocess.Pool(3),参数为同时运行的最大进程数
> 3. 调用apply_async(methondName, args= ())方法，传入进程中执行的函数名和方法 


**代码示例：** 
```python

	import multiprocessing
	import time, os, random
	
	
	def worker(msg):
	    time_start = time.time()
	    print("%s开始执行，进程号为%d" % (msg, os.getpid()))
	    # random.random()随机生成0~1之间的浮点数
	    time.sleep(random.random()*2)
	    time_stop = time.time()
	    print(msg, "执行完毕，耗时%0.2f" % (time_stop-time_start))
	
	
	'''
	    1.pool.close()调用后不能在pool中添加进程
	    2.当使用进程池时必须调用pool.join()方法，让主进程等待所有子进程执行完毕，再继续执行主进程的代码；
	    否则主进程的代码不阻塞，立即执行，执行完毕后主进程结束，程序结束，所有子进程也不复存在
	'''
	
	
	def main():
	    # 创建一个进程池，最大进程数为3
	    pool = multiprocessing.Pool(3)
	    for i in range(0, 10):
	        # Pool.apply_async(要调用的目标，（传递给目标的参数元祖，）)
	        # 每次循环将会用空闲出来的子进程去调用目标
	        pool.apply_async(worker, (i,))
	    print("-----start-----")
	    # 关闭进程池，关闭后pool不再接收新的请求
	    pool.close()
	    # 等待pool中的所有子进程执行完成，必须放在close语句之后
	    pool.join()
	    print("-----end-----")
	
	
	if __name__ == "__main__":
		main()
```

**注意事项:**  

	1. 初始化Pool时，可以指定一个最大进程数，当有新的请求提交到Pool中时，如果池还没有满，那么就会创建,一个新的进程用来执行该请求； 
	   但如果池中的进程数已经达到指定的最大值，那么该请求就会等待，直到池中有进程结束，才会用之前的进程来执行新的任务
	2. pool.close():关闭进程池，关闭后pool不再接收新的请求,即不能在添加任务 
	3. pool.join():阻塞主进程，主进程等待所有子进程执行完毕继续执行
	4. 利用进程池创建的多任务，主进程默认不会等待子进程执行完毕，即不会阻塞。  
	   如果主进程马上执行结束，整个程序执行结束，子进程也强制结束.这一点和线程Thread、Process不同，要特别注意 。  
	   一般会避免这种情况发生：（1）调用pool.join()方法；（2）主进程执行一个带退出条件的死循环等待子进程执行完毕 
	5. 如果要使用Pool创建进程，就需要使用multiprocessing.Manager()中的Queue()，而不是	multiprocessing.Queue()， 
	   否则会得到一条如下的错误信息：
		RuntimeError: Queue objects should only be shared between processes through inheritance

#####5.进程池（Pool） 和 进程队列(Queue) 实现文件夹的拷贝 
**示例代码** ：
```python 

	import multiprocessing
	import os
	import logging
	
	
	def count_dir_num(source_path):
	    """
	    计算一个目录下及其子目录下所有文件的数量
	    :param source_path: 目标目录
	    :return: 文件数量
	    """
	    total_count = 0
	    if os.path.isdir(source_path):
	        files = os.listdir(source_path)
	        for file in files:
	            if os.path.isdir(source_path + "/"+file):
	                total_count += count_dir_num(source_path + "/"+file)
	            else:
	                total_count += 1
	
	    else:
	        total_count += 1
	    return total_count
	
	
	def copy_file(queue, source_file, target_file):
	    """
	    copy文件
	    :param queue :进程间队列
	    :param source_file:源文件
	    :param target_file:目标文件
	    :return:
	    """
	    # global queue
	    rf = open(source_file, "rb")
	    read_data = rf.read()
	    rf.close()
	
	    wf = open(target_file, "wb")
	    wf.write(read_data)
	    wf.close()
	
	    # print(source_file+"拷贝完成!")
	    queue.put(source_file)
	
	
	def copy_dir(pool, queue, source_path, target_path):
	    """
	    copy文件或文件夹
	    :param pool:  进程池
	    :param queue :进程间队列
	    :param source_path:源目录
	    :param target_path:目标目录
	    :return:
	    """
	    try:
	        # 如果目标目录不存在，则创建
	        if os.path.exists(target_path):
	            pass
	        else:
	            os.mkdir(target_path)
	
	        if os.path.isdir(source_path):
	            files = os.listdir(source_path)
	            for file in files:
	                if os.path.isdir(source_path + "/" + file):
	                    copy_dir(pool, queue, source_path + "/" + file, target_path + "/" + file)
	                else:
	                    # print("source_file= "+source_path+"/"+file)
	                    # print("target_file= "+target_path+"/"+file)
	                    # print("开始拷贝"+file+"----->"+target_path+"/"+file)
	                    pool.apply_async(copy_file, args=(queue, source_path + "/" + file, target_path + "/" + file))
	        else:
	            pool.apply_async(copy_file, args=(queue, source_path, target_path))
	    except IOError as e:
	        logging.exception(e)
	
	
	def main():
	    # 1.输入要拷贝的目录
	    source_path = input("请输入要拷贝的文件目录：\n")
	    # 2.生成目标文件夹目录
	    target_path = ""
	    try:
	        target_path = source_path + "_temp"
	        os.mkdir(target_path)
	    except IOError as e:
	        logging.exception(e)
	
	    # 3.定义全局变量进程池
	    pool = multiprocessing.Pool(3)
	    # 4.定义全局变量进程间队列
	    queue = multiprocessing.Manager().Queue()
	
	    print(pool)
	    print(queue)
	
	    # file_names = os.listdir(source_path)
	    # print("file_name= " + str(file_names))
	
	    #     计算要拷贝的总个数
	    total_num = count_dir_num(source_path)
	    print("total_count= " + str(total_num))
	    has_copy_count = 0
	
	    # 5.开始拷贝
	    copy_dir(pool, queue, source_path, target_path)
	
	    # 6.关闭进程池
	    pool.close()
	
	    # pool.join()
	
	    while True:
	        file_name = queue.get() # queue.get()会阻塞，如果没有获取到值，后面的代码都不执行
	        has_copy_count += 1
	        # print("has_copy_count=" + str(has_copy_count))
		# 打印拷贝的进度
	        print("\r拷贝的进度%.2f %%" % (has_copy_count*100/total_num), end="")
		# 退出循环的条件
	        if has_copy_count >= total_num:
	            # print("break")
	            break
	    print()
	
	
	if __name__ == "__main__":
		main()
```